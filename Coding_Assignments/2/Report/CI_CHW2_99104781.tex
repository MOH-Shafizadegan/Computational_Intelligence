\documentclass[]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{listings}
\usepackage[top=1in, right=0.75in, left=0.75in]{geometry}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}

\author{
	Mohammad Hossein Shafizadegan\\
	99104781
}
\title{
	Coding Assignment 2 \\
	Computational Intelligence  \\
	Dr. S. Hajipour
}

\pagestyle{fancy}
\rhead{CI}
\lhead{CHW 2}

\newcommand{\pict}[2]{\begin{center}
		\includegraphics[width=#1\linewidth]{Fig/#2.png}
\end{center}}
\newcommand{\mat}[1]{\begin{bmatrix} #1 \end{bmatrix}}
\newcommand{\deter}[1]{\begin{vmatrix} #1 \end{vmatrix}}

\definecolor{customgreen}{rgb}{0,0.6,0}
\definecolor{customgray}{rgb}{0.5,0.5,0.5}
\definecolor{custommauve}{rgb}{0.6,0,0.8}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=MATLAB,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	frame=single,	                   % adds a frame around the code
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	rulecolor=\color{black},
	breakatwhitespace=true,
	tabsize=3,
	numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
	numbersep=10pt,                   % how far the line-numbers are from the code
	numberstyle=\tiny\color{customgray}, % the style that is used for the line-numbers
}

\begin{document}
	\begin{figure}
		\includegraphics[width=0.25\textwidth]{Fig/Sharif.png}
		\centering
	\end{figure}
	\maketitle
	\tableofcontents
	\newpage
		%-----------------------------------------------------------------------------------------------------------------	
	\section{Question 1}
	\subsection{Dataset overview}
	First we load the provided dataset and extract values of NO emission and speed as$X$ and values of fuel rate as $Y$ correspondingly
	\begin{lstlisting}
		% load data
		data = load('../Data/Ex1.mat');
		X = [data.NOemission' data.speed'];
		Y = data.fuelrate';
	\end{lstlisting}
	Using "scatter3" built-in function, we can visualize our data in the features space.
	\begin{lstlisting}
		figure;
		scatter3(X(:, 1), X(:, 2), Y, 'filled');
		xlabel('NO Emission');
		ylabel('Speed');
		zlabel('Fuel Rate');
		title('Scatter Plot of NO Emission, Speed, and Fuel Rate');
	\end{lstlisting}
	\pict{1}{F1}
	Now we simply choose the first 700 samples as the training set and the others as the validation set using the following code:
	\begin{lstlisting}
		trainX = X(1:700, :);
		trainY = Y(1:700);
		validationX = X(701:end, :);
		validationY = Y(701:end);
	\end{lstlisting}
	\subsection{Linear Regression}
	In this section we aim to fit a linear regression model to our data. Using the MATLAB built-in function called "fitlm" we can simply do so.
	\begin{lstlisting}
		% Fitting a linear regression model using the training set
		linear_model = fitlm(trainX, trainY);
	\end{lstlisting}
	After that we predict the $y$ values for our validation data and training data separately using our linear model. Finally we calculate the Mean Square Error (MSE) and report the results. Here is the code developed for this section
	\begin{lstlisting}
		% Predicting the fuel rate for the training and validation sets
		trainY_pred = predict(linear_model, trainX);
		validationY_pred = predict(linear_model, validationX);
		
		% Calculating MSE for the training and validation sets
		trainMSE = mean((trainY - trainY_pred).^2);
		validationMSE = mean((validationY - validationY_pred).^2);
		
		disp(['Training Set MSE: ' num2str(trainMSE)]);
		disp(['Validation Set MSE: ' num2str(validationMSE)]);
	\end{lstlisting}
	\pict{0.4}{F2}
	Now in order to check if our results make sense, we will plot the resulting hyperplane. In order to do so, we first extract the coefficients of the plane formula from the trained linear model. The next step is to form and plot the hyperplane regarding the coefficients we found before. The code will be as follows:
	\begin{lstlisting}
		% Extracting the coefficients and intercept from the linear regression model
		coefficients = linear_model.Coefficients.Estimate(2:end);
		intercept = linear_model.Coefficients.Estimate(1);
		
		% Creating a meshgrid for the hyperplane visualization
		x1 = linspace(min(X(:, 1)), max(X(:, 1)), 100);
		x2 = linspace(min(X(:, 2)), max(X(:, 2)), 100);
		[X1, X2] = meshgrid(x1, x2);
		Y_pred = coefficients(1) * X1 + coefficients(2) * X2 + intercept;
		
		% Scatter plot of the data points
		figure;
		scatter3(X(:, 1), X(:, 2), Y, 'filled'); hold on;
		
		% Plotting the linear regression hyperplane
		surf(X1, X2, Y_pred, 'FaceAlpha', 0.5, 'EdgeColor', 'none');
	\end{lstlisting} 
	\pict{0.9}{F3}
	It can be seen and inferred that the results are quite reasonable. Also we note that if we had normalized data and then calculate the MSE error, the values for MSE would be much smaller.
	
	\subsection{Logistic Regression}
	For implementing the logistic regression model, we first have to perform the Logit-Transformation for the $y$ values.
	\begin{align*}
		z = \ln \left(\frac{Y - y}{y}\right) = ax + b
	\end{align*}
	\begin{lstlisting}
		Y = max(1.1*trainY);
		log_trainY = log((Y - trainY)./trainY);
	\end{lstlisting}
	Now we create the model just like what we do before:
	\begin{lstlisting}
		% Fitting a logistic regression model using the training set
		logistic_model = fitlm(trainX, log_trainY);
	\end{lstlisting}
	Now we use the model to predict the results for train and validation set. We note that we have to transform the outputs of the model to the previous format by performing the inverse logit-Transform.
	\begin{align*}
		y = \frac{Y}{1 + e^z}
	\end{align*}
	\begin{lstlisting}
		% Predicting the fuel rate probabilities for the training and validation sets
		trainY_pred = predict(logistic_model, trainX);
		trainY_pred = Y ./ (1 + exp(trainY_pred));
		validationY_pred = predict(logistic_model, validationX);
		validationY_pred = Y ./ (1 + exp(validationY_pred));
	\end{lstlisting}
	Now we calculate the MSE correspondingly
	\begin{lstlisting}
		% Calculating MSE for the training and validation sets
		trainMSE = mean((trainY - trainY_pred).^2);
		validationMSE = mean((validationY - validationY_pred).^2);
		
		disp(['Training Set MSE: ' num2str(trainMSE)]);
		disp(['Validation Set MSE: ' num2str(validationMSE)]);
	\end{lstlisting}
	\pict{0.4}{F4}
	Like what we did before, in order to see how the model work, we have plotted the resulting hyperplane after extracting the hyperplane parameters and forming the hyperplane.
	\begin{lstlisting}
		% Extracting model parameters
		coef = logistic_model.Coefficients.Estimate;
		intercept = coef(1);
		weights = coef(2:end);
		
		% Calculating the log-odds (linear combination) for the grid points
		log_odds = intercept + X_grid * weights;
		
		% Applying the logistic (sigmoid) function to obtain probabilities
		Y_grid = max(trainY) ./ (1 + exp(log_odds));
		
		% Reshaping the predicted probabilities to match the grid dimensions
		Y_grid = reshape(Y_grid, size(X1));
		
		% Plotting the decision boundary
		surf(X1, X2, Y_grid, 'EdgeColor', 'none');
		
	\end{lstlisting}
	The results can be seen below which demonstrate the performance of the logistic regression vividly
	\pict{0.9}{F5}
	
	\subsection{Neural Network}
	For this section we have developed a function called "MLP". In this function, we create the network using the built-in function "fitnet" and train it respectively. Then after predicting the $y$ values for the train and validation data, we calculate the MSE error for them and return the resulting values. The code of this function can be seen below:
	\begin{lstlisting}
		function [trainMSE, valMSE] = MLP(n_hidden, trainX, validationX, trainY, validationY)
		
			% Create the MLP model
			net = fitnet(n_hidden);
			
			% Set the training parameters
			net.trainParam.showWindow = false;  % Disable training window display
			net.divideParam.trainRatio = 100/100;
			net.divideParam.testRatio = 0/100;
			net.divideParam.valRatio = 0/100;
			
			% Train the MLP model
			net = train(net, trainX', trainY');
			% Make predictions on the training and validation sets
			trainPred = net(trainX');
			valPred = net(validationX');
			
			% Calculate the MSE for the training and validation sets
			trainMSE = mean((trainPred - trainY').^2);
			valMSE = mean((valPred - validationY').^2);
			
		end
		
	\end{lstlisting}
	Now for different numbers of hidden neurons, we calculate and plot the MSE errors for validation utilizing the previous function we developed.
	\begin{lstlisting}
		n_hidden = 1:20;
		val_MSE_errors = zeros(1,length(n_hidden));
		train_MSE_errors = zeros(1,length(n_hidden));
		
		for i=1:length(n_hidden)
			[train_MSE_errors(i), val_MSE_errors(i)] = MLP(n_hidden(i), trainX, validationX, trainY, validationY);
		end
	\end{lstlisting}
	\pict{0.45}{F6}
	The training and validation error can be seen in the above figure. Regarding both of the above curves, we can infer that perhaps about 13 hidden neurons is the best choice since the validation error has increased after that and the training error is relatively small.\\\\
	It can be vividly inferred from this question that the MLP network with one hidden layer has a much better performance for these data as the MSE values resulting from MLP are much smaller relatively.\\\\
	Linear regression is best for predicting continuous variables and is highly interpretable, but it assumes a linear relationship between inputs and outputs, which limits its use in complex, non-linear scenarios.\\\\
	An MLP with one hidden layer, however, introduces non-linearity through activation functions, allowing it to capture more complex patterns and relationships in the data, making it versatile for both regression and classification.
	
\newpage
	\section{Question 2}
	As of the first step we load the provided dataset and randomly divide the training and validation data. The code for doing so can be seen below:
	\begin{lstlisting}
		% load data
		data = load('../Data/Ex2.mat');
		trainVal_data = data.TrainData;
		test_data = data.TestData;
		
		% Split into training and validation sets (80% training, 20% validation)
		[trainInd, valInd, ~] = dividerand(size(trainVal_data, 2), 0.8, 0.2, 0);
		trainX = trainVal_data(1:3, trainInd);
		trainY = trainVal_data(4, trainInd);
		valX = trainVal_data(1:3, valInd);
		valY = trainVal_data(4, valInd);
		
	\end{lstlisting}
	Now for having a better understanding of our data, here we have visualize the training data for both classes using the following code.
	\begin{lstlisting}
		cls1_idx = find(trainY == 1);
		class1X = trainX(:, cls1_idx);
		
		cls2_idx = find(trainY == 0);
		class2X = trainX(:, cls2_idx);
		
		figure;
		scatter3(class1X(1,:), class1X(2,:), class1X(3,:), 'filled'); hold on;
		scatter3(class2X(1,:), class2X(2,:), class2X(3,:), 'filled');
		
	\end{lstlisting}
	\pict{1}{F14}
	
	\subsection{MLP with one output neuron}
	In this section we aim to design a neural network containing only one output neuron. The network is simply created using built-in function "patternnet()".
	\begin{lstlisting}
		% Define the number of neurons in the hidden layer
		hiddenSize = 10;
		% Create the MLP model
		net = patternnet(hiddenSize);
		net.divideParam.trainRatio = 100/100;
		net.divideParam.testRatio = 0/100;
		net.divideParam.valRatio = 0/100;
		
		% Train the MLP model
		net = train(net, trainX, trainY);
		
		val_predict = round(net(valX));
		error = sum(abs(val_predict - valY));
		disp(error)
	\end{lstlisting}
	Here in order to assess the performance of the network we have calculated the number of the cases the network has estimated the class labels wrongly for validation set and print this value. Also the confusion matrix for training data can be seen below.
	\pict{0.25}{F15}
	Now we simply utilize the trained model for the test data and finally save the predicted labels.
	\begin{lstlisting}
		% Load or define your test data
		testX = test_data(1:3,:);  % Test data features
		
		% Convert the continuous output to binary labels
		predictedLabels = round(net(testX));
		save("Testlabel_a.mat", 'predictedLabels');
	\end{lstlisting}
	
	\subsection{Two output neurons}
	The code for this section with appropriate comments for further explanations is provided below: 
	\begin{lstlisting}
		% Set the number of output neurons to 2
		net.layers{end}.size = 2;
		net.divideParam.trainRatio = 100/100;
		net.divideParam.testRatio = 0/100;
		net.divideParam.valRatio = 0/100;
		% Train the MLP model
		net = train(net, trainX, [1-trainY; trainY]);
		
		val_predict = net(valX);
		% Apply softmax function to obtain class probabilities
		probabilities = softmax(val_predict);
		% Determine the predicted labels based on the maximum probability
		[~, valLabels] = max(probabilities);
		valLabels = valLabels - 1;
		
	\end{lstlisting}
	The first output neuron determines  the probability of the data to belong to the first class with label 0 and the second output layer to the same for the second layer
	After training the model with trainX (input features) and trainY (target labels), it predicts the class probabilities for the validation set valX using the softmax function. Finally, it determines the predicted labels by selecting the class with the highest probability for each example in the validation set. The max function is used to find these labels, which are stored in valLabels. The predicted probabilities can be seen below
	\pict{0.8}{F16}
	Now we apply the network for out test data and stores the resulting labels:
	\begin{lstlisting}
		% Make predictions on the test data
		testY = net(testX);
		
		Y_probabilities = softmax(testY);
		% Determine the predicted labels based on the maximum probability
		[~, yLabels] = max(Y_probabilities);
		yLabels = yLabels - 1;
		
		save("Testlabel_b.mat", 'yLabels');
		
	\end{lstlisting}
	Thereâ€™s no definitive answer as to which design is better; it depends on the context. If interpretability and computational efficiency are priorities, a single output neuron might be preferable. If we want a more detailed probability distribution over the classes, two output neurons might be the better choice.
	
\newpage
	\section{Question 3}
	First we complete the definition of of the derivative of the functions declared in the begging of the notebook as follows:
	\begin{lstlisting}[language=python]
		def sigmoid_prime(x):
			return sigmoid(x) * (1 - sigmoid(x))
			
		def tanh_prime(x):
			return 1 - np.tanh(x)**2
	\end{lstlisting}
	In the main function of the code, we simply define the inputs and outputs based on the truth table:
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'tanh')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			
			y = np.array([0, 1, 1, 0])
			
	\end{lstlisting}
	Now we complete the updating rule based on error back propagation algorithm:
	\begin{lstlisting}[language=python]
		for i in range(len(self.weights)):
			layer = np.atleast_2d(a[i])
			delta = np.atleast_2d(deltas[i])
			self.weights[i] += learning_rate * layer.T.dot(delta)
	\end{lstlisting} 
	Also in the code, we print the value of error every 500 epochs. Also we have a defined an array to store the absolute value of the errors :
	\begin{lstlisting}[language=python]
		error = y[i] - a[-1]
		if (k%500 == 0):
			error_arr.append(abs(error))
			print(f"Epoch {k}, error = {error} \n")
	\end{lstlisting}
	Finally we assign this array as an attribute of the class after the for loop terminated:
	\begin{lstlisting}[language=python]
		self.error_arr = error_arr
	\end{lstlisting}
	As of the next step, we create a function for the NeuralNetwork class to plot and visualize the error through epochs
	\begin{lstlisting}[language=python]
		def plot_errors(self):
			plt.plot(self.error_arr)
			plt.xlabel('Number of epochs x500')
			plt.ylabel('Error')
	\end{lstlisting}
	Now we execute the main function and observe the results below:
	\pict{0.4}{F7}
	The curve demonstrating the error for epochs can be also seen below:
	\pict{0.5}{F8}
	It can be seen vividly that the absolute value of the error has decreased as the model examine more epochs and finally the error will tend to be so close to zero.
	
	\subsection{Part 2}
	In this part we examine the network for logical AND function. We define the output ($y$) correspondingly as follows:
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'tanh')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			# AND
			y = np.array([0, 0, 0, 1])
			
			nn.fit(X, y)
			
			for e in X:
				print(e,nn.predict(e))
	\end{lstlisting}
	\pict{0.5}{F9}
	We do the same for logical OR function too
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'tanh')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			# OR
			y = np.array([0, 1, 1, 1])
			
			nn.fit(X, y)
			
			for e in X:
				print(e,nn.predict(e))
	\end{lstlisting}
	\pict{0.5}{F10}
	
	\subsection{Sigmoid activation function}
	In this part we simply change the activation function to sigmoid one as follows:
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'sigmoid')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			
			y = np.array([0, 1, 1, 0])
			
			nn.fit(X, y)
			
			for e in X:
				print(e,nn.predict(e))
	\end{lstlisting}
	\pict{0.5}{F11}
	Here we assess the logistic activation function for logical AND problem
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'sigmoid')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			# AND
			y = np.array([0, 0, 0, 1])
			
			nn.fit(X, y)
			
			for e in X:
				print(e,nn.predict(e))
	\end{lstlisting}
	\pict{0.5}{F12}
	Here we assess the logistic activation function for logical OR problem
	\begin{lstlisting}[language=python]
		if __name__ == '__main__':
		
			nn = NeuralNetwork([2,2,1],'sigmoid')
			
			X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
			# OR
			y = np.array([0, 1, 1, 1])
			
			nn.fit(X, y)
			
			for e in X:
				print(e,nn.predict(e))
	\end{lstlisting}
	\pict{0.5}{F13}
	As it can be seen below, this code randomly initialize the weight matrices between the input and hidden layers of a neural network every time we create a network. Therefor the results we achieve every time we run the code of this section we expect to see different results.
	\begin{lstlisting}[language=python]
		# input and hidden layers - random((2+1, 2+1)) : 3 x 3
		for i in range(1, len(layers) - 1):
			r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1
			self.weights.append(r)
		# output layer - random((2+1, 1)) : 3 x 1
		r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1
		self.weights.append(r)
	\end{lstlisting}
\end{document}